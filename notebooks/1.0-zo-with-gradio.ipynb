{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba79fce-6861-4e5e-b356-df1582facdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d0f9ee6-c4a9-4cec-a904-be52ff4a8044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f987a2-63f0-4d51-a962-7f080d9a3232",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = pathlib.Path(\"/Users/zihuiouyang/Downloads/images/training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84d642b4-57d2-4e04-883a-7b5f0a8caa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_height, set_width = 180, 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73be5d30-c964-49ff-9f2a-92cbe09d7d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45eb76bf-a004-41e6-90ca-2c408710f369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2392 files belonging to 2 classes.\n",
      "Using 1794 files for training.\n"
     ]
    }
   ],
   "source": [
    "training_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  loaded_data,\n",
    "  subset=\"training\",\n",
    "  validation_split=0.25,\n",
    "  seed=123,\n",
    "  image_size=(set_height, set_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67eb484f-d8f4-4e82-a3fa-874ab63b9211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2392 files belonging to 2 classes.\n",
      "Using 598 files for validation.\n"
     ]
    }
   ],
   "source": [
    "validation_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  loaded_data,\n",
    "  subset=\"validation\",\n",
    "  validation_split=0.25,\n",
    "  seed=123,\n",
    "  image_size=(set_height, set_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c09dcfad-6feb-475c-ac13-6f4061686464",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bb88eec-9a20-4e5b-aff7-87a140a2e8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c03be9-fefc-42fd-8335-de2b06fe11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([layers.experimental.preprocessing.Rescaling(1./255, input_shape=(set_height, set_width, 3)),\n",
    "                   layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "                   layers.MaxPooling2D(),\n",
    "                   layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "                   layers.MaxPooling2D(),\n",
    "                   layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "                   layers.MaxPooling2D(),\n",
    "                   layers.Flatten(),\n",
    "                   layers.Dense(128, activation='relu'),\n",
    "                   layers.Dense(dataset_classes,activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce75d6cf-cd19-44fd-8bce-086fef4a4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "933c685a-8f1d-4ad8-bd71-0f1bdb989483",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc6e0837-5e82-472f-998b-ed953cac5c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zihuiouyang/anaconda3/envs/coqui/lib/python3.9/site-packages/keras/src/backend.py:5729: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 12s 204ms/step - loss: 0.6651 - accuracy: 0.6109 - val_loss: 0.4834 - val_accuracy: 0.7475\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 12s 201ms/step - loss: 0.3647 - accuracy: 0.8283 - val_loss: 0.3439 - val_accuracy: 0.8428\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 12s 204ms/step - loss: 0.2391 - accuracy: 0.9058 - val_loss: 0.3338 - val_accuracy: 0.8679\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 12s 195ms/step - loss: 0.1559 - accuracy: 0.9359 - val_loss: 0.1041 - val_accuracy: 0.9632\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 12s 206ms/step - loss: 0.0853 - accuracy: 0.9699 - val_loss: 0.0977 - val_accuracy: 0.9615\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 12s 198ms/step - loss: 0.0823 - accuracy: 0.9716 - val_loss: 0.2496 - val_accuracy: 0.9047\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 13s 210ms/step - loss: 0.0481 - accuracy: 0.9827 - val_loss: 0.0318 - val_accuracy: 0.9916\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 13s 210ms/step - loss: 0.0154 - accuracy: 0.9961 - val_loss: 1.7506 - val_accuracy: 0.5886\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 12s 199ms/step - loss: 0.3409 - accuracy: 0.8807 - val_loss: 0.0998 - val_accuracy: 0.9615\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 12s 206ms/step - loss: 0.0547 - accuracy: 0.9783 - val_loss: 0.0857 - val_accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "CNN_model = model.fit(\n",
    "  training_images,\n",
    "  validation_data=validation_images,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6559165-b6db-4a7f-84a5-6340f25e439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"no_flip\", \"flip\"]\n",
    "def predict_input_image(img):\n",
    "  img_4d=img.reshape(-1,180,180,3)\n",
    "  prediction=model.predict(img_4d)[0]\n",
    "  return {a[i]: float(prediction[i]) for i in range(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0626e68e-fec9-48a6-836c-451c6cf6935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/61/ndrj3d9x6pvfz7p2n14hzl0m0000gn/T/ipykernel_1523/2691783632.py:1: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  image = gr.inputs.Image(shape=(180,180))\n",
      "/var/folders/61/ndrj3d9x6pvfz7p2n14hzl0m0000gn/T/ipykernel_1523/2691783632.py:1: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  image = gr.inputs.Image(shape=(180,180))\n",
      "/var/folders/61/ndrj3d9x6pvfz7p2n14hzl0m0000gn/T/ipykernel_1523/2691783632.py:2: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  label = gr.outputs.Label(num_top_classes=2)\n",
      "/var/folders/61/ndrj3d9x6pvfz7p2n14hzl0m0000gn/T/ipykernel_1523/2691783632.py:2: GradioUnusedKwargWarning: You have unused kwarg parameters in Label, please remove them: {'type': 'auto'}\n",
      "  label = gr.outputs.Label(num_top_classes=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = gr.inputs.Image(shape=(180,180))\n",
    "label = gr.outputs.Label(num_top_classes=2)\n",
    "gr.Interface(fn=predict_input_image, inputs=image, outputs=label,interpretation='default').launch(debug='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62edac-f70f-4f33-8f7e-56c92950a342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
